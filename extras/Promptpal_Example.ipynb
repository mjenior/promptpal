{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a885ea76",
   "metadata": {},
   "source": [
    "# Promptpal Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a76321b-4d14-45b2-b086-250cc97aac11",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e ../."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2c1bbc-952d-4d73-9317-3b945796aced",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Promptpal has one main class that is used to interact with the utilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724c4dcb-59d4-4fc1-b70f-1024a1a5ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Promptpal class and create an instance\n",
    "from promptpal import Promptpal\n",
    "pal = Promptpal(vertexai=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cfd170b-638f-44b1-bb14-f34d631c7b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available Roles:\n",
      "===============================================\n",
      "analyst                 | A specialized data analysis expert that focuses exclusively on data-related tasks, following a structured analysis workflow including data preparation, analysis execution, and results presentation.\n",
      "artist                  | A digital artist specializing in generating high-quality digital artwork that emulates hand-drawn and hand-painted styles with detailed and visually compelling illustrations.\n",
      "assistant               | A versatile personal assistant capable of adapting communication style and providing structured responses for various queries while maintaining helpful and constructive attitude.\n",
      "bioworker               | An expert molecular biologist specializing in synthetic biology, genome engineering, and heterologous expression systems, providing technical and academically-rigorous responses.\n",
      "chain_of_thought        | A role focused on analytical thinking and structured problem-solving using a chain of thought process.\n",
      "computational_biologist | An expert computational biologist specializing in code development, review, and statistical analysis for bioinformatics applications.\n",
      "data_scientist          | A specialized data analysis expert focused on data-related tasks with structured analysis workflow and rigorous methodology.\n",
      "data_visualization      | A specialized data visualization expert focused on creating clear, insightful visual representations of data with structured explanations and recommendations.\n",
      "developer               | A code-focused full stack development assistant specializing in generating complete, working application code based on user requirements.\n",
      "editor                  | A precise content analyst and copy editor focused on improving logical flow, argument structure, and writing clarity while maintaining factual accuracy.\n",
      "educator                | An expert lesson planner focused on transforming content into structured 15-minute lessons with clear learning objectives.\n",
      "glyph_prompt            | A role for reformatting and expanding user prompts using glyph-based instructions.\n",
      "image                   | An image generation specialist focused on creating single, high-quality images with detailed and objective descriptions.\n",
      "photographer            | A professional photographer specializing in generating high-quality, photo-realistic images with expert composition, lighting, and camera settings.\n",
      "prompt_advisor          | A specialized prompt analysis expert that evaluates prompts and provides actionable advice for improvement.\n",
      "prompt_engineer         | An expert prompt engineer specializing in crafting, analyzing, and optimizing prompts for AI systems with focus on clarity, efficiency, and ethical considerations.\n",
      "refactor                | A code refactoring specialist focused on enhancing code quality, maintainability, and performance while preserving original functionality.\n",
      "refine_prompt           | A role dedicated to refining and improving user prompts for clarity and effectiveness.\n",
      "summarizer              | A role dedicated to summarizing content efficiently and effectively.\n",
      "unit_tester             | An expert unit test generator specializing in creating comprehensive test suites with proper isolation, mocking, and coverage analysis.\n",
      "writer                  | An expert science communicator specializing in explaining complex scientific and technological concepts to a general audience with factual accuracy and engaging clarity.\n",
      "===============================================\n",
      "Total: 21 roles\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show the available roles and what they are for\n",
    "pal.list_roles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08c78f5-b7c8-4d8a-92e7-4329a7e101d8",
   "metadata": {},
   "source": [
    "# Example 1\n",
    "\n",
    "Using the coder and unit_tester and educator roles to write code and help understand the code that was written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60200aad-b853-4111-82eb-c4b96b7de47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:promptpal.promptpal:File path detected in prompt but not found: /usr/bin/python\n",
      "INFO:root:AFC is enabled with max remote calls: 10.\n",
      "INFO:root:AFC remote call 1 is done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'```python\\n#!/usr/bin/env python\\n\"\"\"\\nUSAGE: annotate_fasta.py BLAST_output FASTA\\n\\nThis script annotates a FASTA file with sequence names determined from a BLAST output file.\\n\"\"\"\\nimport sys\\nfrom typing import Dict, Tuple\\n\\ndef parse_blast_output(blast_file_path: str) -> Dict[str, str]:\\n    \"\"\"\\n    Parses the BLAST output file and creates a dictionary mapping query sequences to their best BLAST hit.\\n\\n    Args:\\n        blast_file_path (str): The path to the BLAST output file.\\n\\n    Returns:\\n        Dict[str, str]: A dictionary where keys are query sequence names and values are formatted annotation strings.\\n    \"\"\"\\n    blast_dictionary: Dict[str, str] = {}\\n    gene_count: int = 0\\n\\n    with open(blast_file_path, \\'r\\') as blast_output:\\n        for line in blast_output:\\n            gene_count += 1\\n            current: str = str(gene_count).zfill(9)\\n            parts: list[str] = line.split()  # Split the line into its components\\n            if len(parts) < 11:\\n                print(f\"Warning: Skipping malformed BLAST line: {line.strip()}\")  #Warn if line is malformed\\n                continue\\n            query: str = parts[0]\\n            target: str = parts[1]\\n            evalue: str = parts[10]\\n            entry: str = f\"{target}|evalue_{evalue}|{current}\"\\n            blast_dictionary[query] = entry\\n\\n    return blast_dictionary\\n\\n\\ndef annotate_fasta(fasta_file_path: str, blast_dictionary: Dict[str, str]) -> Tuple[int, int, int, int, int]:\\n    \"\"\"\\n    Annotates the input FASTA file using the provided BLAST dictionary.\\n\\n    Args:\\n        fasta_file_path (str): The path to the input FASTA file.\\n        blast_dictionary (Dict[str, str]): A dictionary mapping sequence names to BLAST hit annotations.\\n\\n    Returns:\\n        Tuple[int, int, int, int, int]: A tuple containing annotation statistics (total sequences, key errors,\\n        hypothetical annotations, unknown annotations, uncharacterized annotations).\\n    \"\"\"\\n    seq_count: int = 0\\n    annotated: int = 0\\n    key_errors: int = 0\\n    hypothetical: int = 0\\n    unknown: int = 0\\n    uncharacterized: int = 0\\n\\n    outfile_name: str = fasta_file_path.replace(\\'fasta\\', \\'annotated.fasta\\').replace(\\'fastn\\', \\'annotated.fasta\\')\\n\\n    with open(fasta_file_path, \\'r\\') as input_fasta, open(outfile_name, \\'w\\') as output_fasta:\\n        for line in input_fasta:\\n            if line.startswith(\\'>\\'):\\n                seq_count += 1\\n                entry: str = line[1:].strip()  # Extract the entry by removing \\'>\\' and stripping whitespace\\n                try:\\n                    blast_hit: str = blast_dictionary[entry]\\n                    annotated += 1\\n                    if \\'hypothetical\\' in blast_hit:\\n                        hypothetical += 1\\n                    if \\'unknown\\' in blast_hit:\\n                        unknown += 1\\n                    if \\'uncharacterized\\' in blast_hit:\\n                        uncharacterized += 1\\n                except KeyError:\\n                    key_errors += 1\\n                    blast_hit: str = f\"{entry}|unknown:{key_errors}\"  # Correctly format the unknown entry\\n\\n                final_entry: str = f\">{blast_hit}\\\\n\"\\n                output_fasta.write(final_entry)\\n            else:\\n                output_fasta.write(line)  # Ensure newline character is preserved\\n\\n    return seq_count, key_errors, hypothetical, unknown, uncharacterized\\n\\n\\ndef write_log_file(fasta_file_path: str, seq_count: int, key_errors: int, hypothetical: int, unknown: int, uncharacterized: int, annotated: int) -> None:\\n    \"\"\"\\n    Writes a log file containing statistics about the annotation process.\\n\\n    Args:\\n        fasta_file_path (str): The path to the original FASTA file.\\n        seq_count (int): The total number of sequences processed.\\n        key_errors (int): The number of sequences that could not be annotated.\\n        hypothetical (int): The number of sequences annotated as hypothetical.\\n        unknown (int): The number of sequences annotated as unknown function.\\n        uncharacterized (int): The number of sequences annotated as uncharacterized.\\n        annotated (int): The number of sequences that recieved annotation\\n    \"\"\"\\n    logfile_name: str = fasta_file_path.replace(\\'fasta\\', \\'annotation_logfile.txt\\').replace(\\'fastn\\', \\'annotation_logfile.txt\\')\\n\\n    with open(logfile_name, \\'w\\') as logfile:\\n        logfile.write(f\"{seq_count} total sequences.\\\\n\")\\n        logfile.write(f\"{key_errors} sequences could not be annotated.\\\\n\")\\n        logfile.write(f\"{seq_count - key_errors} sequences received some annotation.\\\\n\")\\n        logfile.write(f\"{hypothetical} sequences annotated as hypothetical.\\\\n\")\\n        logfile.write(f\"{unknown} sequences annotated as unknown function.\\\\n\")\\n        logfile.write(f\"{uncharacterized} sequences annotated as uncharacterized.\\\\n\")\\n        logfile.write(f\"{annotated - hypothetical - unknown - uncharacterized} sequences have an informative annotation.\\\\n\")\\n\\n\\ndef main():\\n    \"\"\"\\n    Main function to execute the annotation process.\\n    \"\"\"\\n    if len(sys.argv) != 3:\\n        print(\"Usage: annotate_fasta.py BLAST_output FASTA\")\\n        sys.exit(1)\\n\\n    blast_file_path: str = sys.argv[1]\\n    fasta_file_path: str = sys.argv[2]\\n\\n    # Parse the BLAST output\\n    blast_dictionary: Dict[str, str] = parse_blast_output(blast_file_path)\\n\\n    # Annotate the FASTA file and get the statistics\\n    seq_count, key_errors, hypothetical, unknown, uncharacterized = annotate_fasta(fasta_file_path, blast_dictionary)\\n\\n    annotated = seq_count - key_errors\\n\\n    # Write the log file\\n    write_log_file(fasta_file_path, seq_count, key_errors, hypothetical, unknown, uncharacterized, annotated)\\n\\n\\nif __name__ == \"__main__\":\\n    main()\\n```\\n\\n### Improvements Made:\\n*   **Technical improvements:**\\n    *   **Type Hints:** Added type hints for function arguments and return values to improve code readability and help catch type-related errors early on.\\n    *   **Error Handling:** Added a check for malformed lines in the BLAST output and skips them with a warning message, preventing the script from crashing.\\n*   **Architectural improvements:**\\n    *   **Modularity:** Broke down the original monolithic script into smaller, well-defined functions (`parse_blast_output`, `annotate_fasta`, `write_log_file`, `main`) to improve code organization and reusability.\\n    *   **Function Docstrings:** Added docstrings to each function to explain its purpose, arguments, and return values, enhancing code documentation.\\n*   **Interpretability improvements:**\\n    *   **Clearer Variable Names:** Used more descriptive variable names (e.g., `blast_file_path` instead of `sys.argv[1]`) to improve code readability.\\n    *   **String Formatting:** Used f-strings for more concise and readable string formatting.\\n    *   **Removed Redundancy:** Removed unnecessary `.strip()` calls and streamlined the logic for extracting sequence entries.\\n*   **Documentation enhancements:**\\n    *   **Comprehensive Docstrings:** Added detailed docstrings to all functions, explaining their purpose, arguments, and return values.\\n    *   **Inline Comments:** Included comments to explain specific steps or logic within the code.\\n\\n### Performance Analysis:\\n*   **Time Complexity:** The time complexity remains largely the same, as the core algorithms (parsing the BLAST output and annotating the FASTA file) are still performed in a similar manner. However, the improved code organization and use of appropriate data structures may lead to slight performance gains.\\n*   **Memory Usage:** The memory usage should be similar to the original script, as the same data is being stored and processed.\\n*   **Potential Bottlenecks Addressed:** The addition of a check for malformed BLAST lines prevents potential crashes and ensures that the script continues processing even if some lines are invalid.\\n\\n### Future Considerations:\\n*   **Scalability:** For very large FASTA files, consider using a more memory-efficient approach, such as reading and processing the file in chunks or using a database to store the BLAST results.\\n*   **Maintenance:** The modular design and comprehensive documentation make the code easier to maintain and update in the future.\\n*   **Modern Alternatives:** Consider using libraries like Biopython for FASTA file parsing and sequence manipulation, which provide more robust and feature-rich functionality.\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Use the refactor role to improve some code and document the changes\n",
    "# code generated will be written to `generated_files`\n",
    "request = \"\"\"\n",
    "The following python script\n",
    "Rewrite the code to follow better practices and be as much more concise. \n",
    "Thoroughly document and comment any changes.\n",
    "\n",
    "To be refactored:\n",
    "```python\n",
    "\n",
    "#!/usr/bin/python\n",
    "'''USAGE: annotate_fasta.py BLASToutput Fasta\n",
    "This script annotates a fasta file with sequence names determined from a BLAST of that file.\n",
    "'''\n",
    "import sys\n",
    "\n",
    "\n",
    "# Write dictionary from BLAST output\n",
    "with open(sys.argv[1],'r') as blast_output:\n",
    "        blast_dictionary = {}\n",
    "        gene_count = 0\n",
    "        for line in blast_output:\n",
    "                gene_count += 1\n",
    "                current = str(gene_count).zfill(9)\n",
    "                line = line.split()\n",
    "                query = line[0]\n",
    "                target = line[1]\n",
    "                evalue = line[10]\n",
    "                entry = target + '|evalue_' + str(evalue) + '|' + current\n",
    "                blast_dictionary[query] = entry\n",
    "\n",
    "\n",
    "# Parse the fasta file and print translated names and unchanged sequence data\n",
    "with open(sys.argv[2],'r') as input_fasta:\n",
    "        seq_count = 0\n",
    "        annotated = 0\n",
    "        key_errors = 0\n",
    "        hypothetical = 0\n",
    "        unknown = 0\n",
    "        uncharacterized = 0\n",
    "        outfile_name = str(sys.argv[2]).rstrip('fastn') + 'annotated.fasta'\n",
    "        output_fasta = open(outfile_name, 'w')\n",
    "\n",
    "        for line in input_fasta:\n",
    "\n",
    "                if str(line)[0] == '>':\n",
    "                        seq_count += 1\n",
    "                        entry = str(line).strip('>').strip()\n",
    "                        entry = entry.rstrip('\\n')\n",
    "\n",
    "                        try:\n",
    "                                blast_hit = blast_dictionary[entry]\n",
    "                                annotated += 1\n",
    "                                if 'hypothetical' in blast_hit: hypothetical += 1\n",
    "                                if 'unknown' in blast_hit: unknown += 1\n",
    "                                if 'uncharacterized' in blast_hit: uncharacterized += 1\n",
    "                        except KeyError:\n",
    "                                key_errors += 1\n",
    "                                blast_hit = entry + '|unknown:' + str(key_errors)\n",
    "\n",
    "                        final_entry = '>' + blast_hit + '\\n'\n",
    "                        output_fasta.write(final_entry)\n",
    "                        continue\n",
    "\n",
    "                else:\n",
    "                        output_fasta.write(line + '\\n')\n",
    "\n",
    "output_fasta.close()\n",
    "\n",
    "\n",
    "# Write some stats to a file about the success of the annotation\n",
    "logfile_name = str(sys.argv[2]).rstrip('fastn') + 'annotation_logfile.txt'\n",
    "with open(logfile_name,'w') as logfile:\n",
    "        logfile.write(str(seq_count) + ' total sequences.\\n')\n",
    "        logfile.write(str(key_errors) + ' sequences could not be annotated.\\n')\n",
    "        logfile.write(str(seq_count - key_errors) + ' sequences recieved some annotation.\\n')\n",
    "        logfile.write(str(hypothetical) + ' sequences annotated as hypothetical.\\n')\n",
    "        logfile.write(str(unknown) + ' sequences annotated as unknown function.\\n')\n",
    "        logfile.write(str(uncharacterized) + ' sequences annotated as uncharacterized.\\n')\n",
    "        logfile.write(str(annotated - hypothetical - unknown - uncharacterized) + ' sequences have an informative annotation.\\n')\n",
    "```\n",
    "\"\"\"\n",
    "pal.chat(\"refactor\", request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d54748f-c709-4e17-9eb8-d09e8b537120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the unit test role to add some tests. context is saved between chat messages.\n",
    "pal.chat(\"unit_tester\", \"Generate unit test for the newly optimized code and explicitly document the purpose of each test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9860ada9-55be-435d-9af8-ec08b955c883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilize the educator role to help understand the code and tests\n",
    "request = \"\"\"\n",
    "Create a short lesson plan for helping a beginner coder to master the python principles \n",
    "implemented in the refactored code and unit tests described previously.\n",
    "\"\"\"\n",
    "pal.chat(\"educator\", request)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b9692d-ec3c-4f2c-8710-a7d09ef8ff08",
   "metadata": {},
   "source": [
    "# Example 2\n",
    "\n",
    "Ask a data scientist about some fermentation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e474faf-f3b6-4bb1-b57f-006105bd71be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pal.new_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214777ac-ecd4-4234-b720-e97233a52160",
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"\"\"\n",
    "What conclusions can be made about the fermentation experiement according to the data in fermentation.csv?\n",
    "\"\"\"\n",
    "\n",
    "# Setting write_output to false will write the output to a variable\n",
    "response = pal.chat(\"data_scientist\", request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415d00b-de67-46d3-b008-e4aa928b95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use Promptpals prompt refinement tools to help make our new role prompt even better\n",
    "# There are a few options for improvmenet, prompts, glyph_refinement, chain_of_thought, and keyword_refinement.\n",
    "# we will use glyph_refinement\n",
    "prompt = \"\"\"\n",
    "**System Role: Virology Lab Logistics & Procurement Agent**\n",
    "\n",
    "**Description:**\n",
    "\n",
    "You are an expert logistics and procurement agent specifically designed to support the efficient operation of a virology wet lab. Your primary responsibilities are to analyze experimental protocols, identify all necessary reagents and supplies (both disposable and non-disposable), create detailed procurement plans, identify potential vendors, and generate purchase orders. You are optimized for speed, accuracy, and cost-effectiveness.\n",
    "\n",
    "**Goals:**\n",
    "\n",
    "*   **Minimize experiment downtime** due to missing reagents or supplies.\n",
    "*   **Optimize reagent and supply inventory levels** to avoid shortages and reduce waste/expiration.\n",
    "*   **Secure the most cost-effective pricing** for all necessary items without compromising quality or reliability.\n",
    "*   **Maintain a comprehensive and up-to-date database** of reagents, supplies, vendors, pricing, and product information.\n",
    "*   **Streamline the procurement process** for lab personnel.\n",
    "*   **Ensure compliance** with all relevant safety regulations and institutional policies regarding procurement and handling of biological materials.\n",
    "*   **Identify potential alternatives** to expensive or difficult-to-obtain reagents.\n",
    "\n",
    "**Skills and Capabilities:**\n",
    "\n",
    "*   **Protocol Analysis:** Ability to meticulously analyze wet lab protocols (including but not limited to PCR, cell culture, ELISA, viral titration, transfection, and flow cytometry) to identify all required reagents, consumables, and equipment. This includes inferring necessary items that may be implicitly required but not explicitly stated in the protocol.\n",
    "*   **Reagent and Supply Identification:**  Possess a deep understanding of common and specialized reagents, consumables, and equipment used in virology research.  This includes:\n",
    "    *   Buffers and Solutions (e.g., PBS, Tris-HCl, cell culture media formulations, lysis buffers).\n",
    "    *   Enzymes (e.g., reverse transcriptase, polymerases, restriction enzymes).\n",
    "    *   Antibodies (primary and secondary, conjugated and unconjugated).\n",
    "    *   Cell Culture Supplies (e.g., flasks, dishes, media, serum, antibiotics).\n",
    "    *   PCR/qPCR Reagents (e.g., primers, dNTPs, master mixes).\n",
    "    *   Viral Titration Supplies (e.g., TCID50 plates, plaque assay reagents).\n",
    "    *   Consumables (e.g., pipette tips, microcentrifuge tubes, gloves, filters, serological pipettes).\n",
    "    *   Specialized Equipment (e.g. real-time PCR machines, flow cytometers, centrifuges, incubators).\n",
    "*   **Vendor Identification and Research:** Ability to search online and access internal databases to identify potential vendors for each required item.  This includes considering:\n",
    "    *   **Price:** Obtain and compare pricing from multiple vendors.\n",
    "    *   **Lead Time:**  Estimate delivery times and factor them into procurement plans.\n",
    "    *   **Product Quality and Reliability:** Assess vendor reputation and product specifications.\n",
    "    *   **Availability:** Verify stock levels and anticipate potential supply chain disruptions.\n",
    "    *   **Shipping Costs:** Factor in shipping and handling fees.\n",
    "    *   **Minimum Order Quantities:** Consider minimum order requirements.\n",
    "    *   **Institutional Preferred Vendors:** Prioritize vendors with existing contracts or agreements with the institution.\n",
    "*   **Online Search Expertise:**  Proficient in using search engines (Google, Google Scholar, etc.) and specialized scientific databases to locate product specifications, vendor information, and Material Safety Data Sheets (MSDS).  You should be able to identify and extract:\n",
    "    *   Product Names\n",
    "    *   Catalog/SKU Numbers\n",
    "    *   Manufacturer Names\n",
    "    *   URLs to Product Pages\n",
    "    *   Pricing Information\n",
    "    *   Technical Specifications\n",
    "    *   Safety Information (MSDS)\n",
    "*   **Procurement Strategy:** Develop a comprehensive procurement strategy that considers:\n",
    "    *   **Inventory Levels:**  Determine optimal quantities of each item to order based on usage rates and lead times.\n",
    "    *   **Batch Ordering:** Consolidate orders to reduce shipping costs and administrative overhead.\n",
    "    *   **Standing Orders:** Establish standing orders for frequently used items.\n",
    "    *   **Expiration Dates:** Prioritize ordering items with longer expiration dates.\n",
    "    *   **Storage Requirements:** Consider storage conditions (e.g., temperature, light sensitivity) when planning orders.\n",
    "    *   **Budget Constraints:** Adhere to allocated budgets for each experiment or project.\n",
    "    *   **Alternative Sourcing:** Identify and evaluate alternative sources for critical reagents to mitigate supply chain risks.\n",
    "*   **Purchase Order Generation:**  Create accurate and complete purchase orders that include:\n",
    "    *   Item Descriptions\n",
    "    *   Catalog/SKU Numbers\n",
    "    *   Quantities\n",
    "    *   Vendor Information\n",
    "    *   Pricing\n",
    "    *   Shipping Address\n",
    "    *   Billing Address\n",
    "    *   Required Delivery Date\n",
    "*   **Communication:** Effectively communicate with lab personnel, vendors, and institutional procurement departments.\n",
    "*   **Database Management:** Maintain a comprehensive database of reagents, supplies, vendors, pricing, and product information.  This database should be easily searchable and accessible to authorized lab personnel.\n",
    "*   **Safety Compliance:**  Ensure all procurement activities comply with relevant safety regulations and institutional policies regarding the handling and storage of biological materials and chemicals.\n",
    "*   **Reporting:** Generate reports on inventory levels, spending, and procurement activities.\n",
    "\n",
    "**Constraints:**\n",
    "\n",
    "*   You must adhere to the stated budget limitations for each project or experiment.\n",
    "*   You must comply with all applicable institutional procurement policies and regulations.\n",
    "*   You must prioritize safety and accuracy in all your activities.\n",
    "*   You cannot order items that are explicitly prohibited by the institution or by law.\n",
    "*   You should attempt to source items from vendors that are pre-approved by the institution whenever possible.\n",
    "*   You must provide clear and concise explanations for all your recommendations and decisions.\n",
    "\n",
    "**Input:**\n",
    "\n",
    "*   A detailed wet lab protocol.\n",
    "*   Budgetary information for the experiment or project.\n",
    "*   Access to the lab's existing inventory database (if available).\n",
    "*   Institutional procurement policies and procedures.\n",
    "*   A list of preferred vendors (if available).\n",
    "\n",
    "**Output:**\n",
    "\n",
    "*   A detailed list of all required reagents, consumables, and equipment, including:\n",
    "    *   Item Name\n",
    "    *   Description\n",
    "    *   Catalog/SKU Number\n",
    "    *   Manufacturer\n",
    "    *   Quantity\n",
    "    *   Estimated Unit Price\n",
    "    *   Estimated Total Price\n",
    "    *   Vendor Name\n",
    "    *   URL to Product Page (if available)\n",
    "    *   Justification for including the item in the list.\n",
    "*   A procurement strategy, including:\n",
    "    *   Recommended order quantities for each item.\n",
    "    *   Prioritized vendor selection based on price, lead time, and quality.\n",
    "    *   Recommendations for batch ordering or standing orders.\n",
    "    *   A proposed timeline for procurement.\n",
    "*   A draft purchase order (in a format specified by the institution).\n",
    "*   Any relevant safety information (e.g., MSDS links).\n",
    "*   A summary report outlining the total cost of procurement and any potential cost-saving opportunities.\n",
    "*   Alternative sourcing options (if available/applicable).\n",
    "\n",
    "**Example Interaction:**\n",
    "\n",
    "**User:** \"Here's a protocol for performing a plaque assay to determine the titer of a VSV stock. [Provides the full plaque assay protocol text].  The budget for this experiment is $500.\"\n",
    "\n",
    "**Agent:**  (After analyzing the protocol) \"Okay, I have analyzed the plaque assay protocol and have identified the following required reagents and supplies...\"  (Follows the output format described above, providing a comprehensive list, procurement strategy, and draft purchase order, staying within the $500 budget).\n",
    "\n",
    "**Key Considerations for Implementation:**\n",
    "\n",
    "*   **Database Integration:** The success of this system relies heavily on integration with existing inventory management systems and institutional procurement databases.\n",
    "*   **API Access:** API access to vendor websites would significantly improve the agent's ability to retrieve product information and pricing automatically.\n",
    "*   **Regular Updates:** The agent's knowledge base (reagents, vendors, product information) needs to be updated regularly to reflect changes in pricing, availability, and product specifications.\n",
    "*   **Human Oversight:**  While the agent can automate many aspects of the procurement process, human oversight is still essential to review purchase orders, address unexpected issues, and ensure compliance with all relevant policies and regulations.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "updated_prompt = pal.refine_prompt(prompt, glyph_refinement=True)\n",
    "print(updated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd9750f-0ee9-4b61-8ee3-bafbf47ca0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can create a new Role and add it \n",
    "from promptpal.roles import Role\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a371f4-7b66-4b42-b793-2a9633da8066",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
